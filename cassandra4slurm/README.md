# Cassandra4Slurm main options

Cassandra4Slurm is a tool that provides automatic deployment of a
Cassandra cluster in a slurm-based system. 

This tool can be used just to
launch a Cassandra cluster alone or to launch a Cassandra cluster together
with a client application. In the first scenario the Cassandra cluster
will run until the allocation time expires or until the user explicitly
stops it. In the second scenario, there is also the option of ending
automatically the Cassandra cluster when the application ends the
execution.

This tool can be used in two different modes:

-   As the independent command _c4s_.

-   Integrated with the _enqueue_compss_ command, when executing PyCOMPSs
    applications

## c4s command

This command is in the directory \$HECUBA_ROOT/bin, where HECUBA_ROOT
points to the base directory of Hecuba.

The c4s command is composed by several bash scripts that need to set
some environment variables that the jobs launched by slurm need to use.
For this reason, it is necessary to execute it preceded by ".": . c4s

For example, to start from scratch a Cassandra cluster composed of 2 nodes during 1 hour using the debug queue of the queue system, the user could run the following command:

'''
. c4s RUN -nC=2 -t=01:00:00 --qos=debug
'''

The c4s command performs the following five steps:

1.  Request allocation of nodes.

 A Slurm allocation requires the number of nodes to allocate and the time to execute.
 Cassandra4Slurm defines 4 options related to the number of nodes to
 allocate:

 * -nT=N: total number of nodes (N) to allocate

 * -nC=N: number of nodes (N) that will run Cassandra processes

 * -nA=N: number of nodes (N) that will run Application processes

 * -disjoint: this option sets a disjoint allocation for Cassandra and the
   application, therefore nT=nC+nA where nC nodes will run Cassandra processes and nA
   nodes will run application processes; by default (without setting this option) the
   nT=max(nC,nA) and some of the nodes will run *both* Cassandra and application
   processes.

 In addition, the user has to specify the maximum execution time of the
 job (option -t). For example: -t=00:05:00 specifies a maximum
 execution time of 5 minutes.

 The script also passes to the slurm command all parameters indicated
 by the user. For example, the user can specify that the target queue
 for the job is the debug queue using the option \--qos=debug

2.  Adapt Cassandra configuration files to the allocation

 Once the allocation is granted, cassandra4Slurm adapts the
 configuration files according to the allocation. By
 default, this tool stores the content of the database in the local disk of the
 allocated nodes.

3.  Start Cassandra cluster execution in the allocation

 There are two options:

  * From *scratch* (option RUN)

  * From a *snapshot generated by a previous execution* (option RECOVER).
    In this case, it is necessary to introduce the snapshot identifier
    with the option -r=id_snapshot (which was assigned when the snapshot
    was generated). If the user does not use the -r option, then the
    tool lists the identifiers of all the snapshots stored and requests
    the user to introduce the identifier of the snapshot that wants to
    recover.

4.  Optionally start the application execution

 The option -A="command" starts the execution of an application with the
 indicated parameters once the Cassandra cluster is up. The application
 can be any command:

  * An executable file

  * A python script

  * A PyCOMPSs application, in which case the \--pycompss option is used
    to configure all the PyCOMPSs environment.

 This option combined with the -f option causes to stop the Cassandra
 cluster when the application ends the execution.

5.  Optionally save the snapshot of the database at the end of the
    execution

   The option -s creates a snapshot of the content of the database
   when the Cassandra cluster finalizes its execution. The resulting 
   snapshot will be stored in the snapshot directory (this directory is specified
   setting a configuration variable).

Users can also use the c4s command to stop a Cassandra cluster (option
STOP, without any other parameter) or to check the status of the cluster
(option STATUS, without any other parameter). If the user needs to
cancel the execution of the job, without completing the insertions and
without generating snapshots, then can use the option KILL.

The following table summarizes the options of the c4s command:

  -----------------------------------------------------------------------
  **Options**             **Valid           **Description**
                          parameters**      
  ----------------------- ----------------- -----------------------------
  RUN                     -nT, -nC, -nA,    Starts a new cluster from
                          -A, -s, -f (if -A scratch
                          is used),         
                          -disjoint, -t,    
                          \--qos (and other 
                          slurm parameters) 

  RECOVER                 -s, -r, -A, -f    Starts a new cluster from a
                          (if -A is used)   snapshot
                          \--qos (and other 
                          slurm parameters) 

  STOP                    None              Stops the cluster in a
                                            controlled way (generates
                                            snapshot if required)

  STATUS                  None              Shows the status of the
                                            cluster

  KILL                    None              Cancels the slurm job (no
                                            snapshot is generated)
  -----------------------------------------------------------------------

## Integration with enqueue_compss command

The enqueue_compss command launches PyCOMPSs applications on slurm based
systems. This command is integrated with cassandra4Slurm and is able to
deploy a Cassandra cluster previous to the execution of the application
or to connect with a previously deployed cluster. This deployment
launches a Cassandra process on each worker node of COMPSs (i.e. the
application and Cassandra are sharing all the nodes).

To enable the deployment of the Cassandra cluster, the user must use two
options of the enqueue_compss command:

*   storage_home=path, where path points to the Hecuba directory that
    contains the implementation of the COMPSs storage interface
    (usually, \$HECUBA_ROOT/compss, where HECUBA_ROOT points to the base
    directory of Hecuba)

*   storage_props=hecuba.cfg, where hecuba.cfg is a file created by the
    user with the options to configure the deployment of Cassandra (it
    can be an empty file).

The options that configure the deployment of Cassandra when using
enqueue_compss:

*   export RECOVER=id_snapshot: to start the Cassandra cluster from the
    snapshot

*   export MAKE_SNAPSHOT=True: to generate a snapshot once the
    application ends the execution

*   export CONTACT_NAMES=\[IP1,IP2,IP3...\]: to avoid the creation of a
    new Cassandra cluster and to connect with the existing Cassandra cluster
    indicated in the CONTACT_NAMES

# Configuration files and variables

The first time a user launches cassandra4Slurm it creates the following
configuration file: \$HOME/.c4s/cassandra4slurm.cfg. This file contains
the definition of some variables that the user can adapt as needed:

*   LOG_PATH: target directory for c4s log files (default
    \$HOME/.c4s/logs)

*   DATA_PATH: target directory to store the content of the database
    (default /scratch/tmp)

*   CASS_HOME: Cassandra home directory (default
    \$HECUBA_ROOT/cassandra-d8tree, where HECUBA_ROOT is a variable that
    points to the base directory of Hecuba)

*   SNAP_PATH: directory that will hold the snapshots that
    cassandra4Slurm creates (default /scratch/tmp/hecuba/snapshots)

*   CASSANDRA_LOG_DIR: target directory for the Cassandra execution logs
    (default \$HOME/.c4s/logs)
